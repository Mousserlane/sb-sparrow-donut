{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Load dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "\n",
    "mp.set_start_method(\"spawn\", force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "import os\n",
    "\n",
    "\n",
    "login(os.environ.get(\"HF_TOKEN\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"mousserlane/id_receipt_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "example = dataset[\"train\"][0]\n",
    "image = example[\"image\"]\n",
    "# let's make the image a bit smaller when visualizing\n",
    "width, height = image.size\n",
    "display(image.resize((int(width * 0.2), int(height * 0.2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# let's load the corresponding JSON dictionary (as string representation)\n",
    "ground_truth = example[\"ground_truth\"]\n",
    "print(ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "\n",
    "literal_eval(ground_truth)[\"gt_parse\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Load model and processor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from transformers import VisionEncoderDecoderConfig\n",
    "\n",
    "max_length = 768\n",
    "image_size = [1280, 960]\n",
    "\n",
    "# update image_size of the encoder\n",
    "# during pre-training, a larger image size was used\n",
    "config = VisionEncoderDecoderConfig.from_pretrained(\"naver-clova-ix/donut-base\")\n",
    "config.encoder.image_size = image_size  # (height, width)\n",
    "# update max_length of the decoder (for generation)\n",
    "config.decoder.max_length = max_length\n",
    "# TODO we should actually update max_position_embeddings and interpolate the pre-trained ones:\n",
    "# https://github.com/clovaai/donut/blob/0acc65a85d140852b8d9928565f0f6b2d98dc088/donut/model.py#L602"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from transformers import DonutProcessor, VisionEncoderDecoderModel, BartConfig\n",
    "\n",
    "processor = DonutProcessor.from_pretrained(\"naver-clova-ix/donut-base\")\n",
    "model = VisionEncoderDecoderModel.from_pretrained(\n",
    "    \"naver-clova-ix/donut-base\", config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import json\n",
    "# import random\n",
    "# from typing import Any, List, Tuple\n",
    "\n",
    "# import torch\n",
    "# from torch.utils.data import Dataset\n",
    "\n",
    "# added_tokens = []\n",
    "\n",
    "\n",
    "# class DonutDataset(Dataset):\n",
    "#     \"\"\"\n",
    "#     DonutDataset which is saved in huggingface datasets format. (see details in https://huggingface.co/docs/datasets)\n",
    "#     Each row, consists of image path(png/jpg/jpeg) and gt data (json/jsonl/txt),\n",
    "#     and it will be converted into input_tensor(vectorized image) and input_ids(tokenized string).\n",
    "#     Args:\n",
    "#         dataset_name_or_path: name of dataset (available at huggingface.co/datasets) or the path containing image files and metadata.jsonl\n",
    "#         max_length: the max number of tokens for the target sequences\n",
    "#         split: whether to load \"train\", \"validation\" or \"test\" split\n",
    "#         ignore_id: ignore_index for torch.nn.CrossEntropyLoss\n",
    "#         task_start_token: the special token to be fed to the decoder to conduct the target task\n",
    "#         prompt_end_token: the special token at the end of the sequences\n",
    "#         sort_json_key: whether or not to sort the JSON keys\n",
    "#     \"\"\"\n",
    "\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         dataset_name_or_path: str,\n",
    "#         max_length: int,\n",
    "#         split: str = \"train\",\n",
    "#         ignore_id: int = -100,\n",
    "#         task_start_token: str = \"<s>\",\n",
    "#         prompt_end_token: str = None,\n",
    "#         sort_json_key: bool = True,\n",
    "#     ):\n",
    "#         super().__init__()\n",
    "\n",
    "#         self.max_length = max_length\n",
    "#         self.split = split\n",
    "#         self.ignore_id = ignore_id\n",
    "#         self.task_start_token = task_start_token\n",
    "#         self.prompt_end_token = (\n",
    "#             prompt_end_token if prompt_end_token else task_start_token\n",
    "#         )\n",
    "#         self.sort_json_key = sort_json_key\n",
    "\n",
    "#         self.dataset = load_dataset(dataset_name_or_path, split=self.split)\n",
    "#         self.dataset_length = len(self.dataset)\n",
    "\n",
    "#         self.gt_token_sequences = []\n",
    "#         for sample in self.dataset:\n",
    "#             ground_truth = json.loads(sample[\"ground_truth\"])\n",
    "#             if (\n",
    "#                 \"gt_parses\" in ground_truth\n",
    "#             ):  # when multiple ground truths are available, e.g., docvqa\n",
    "#                 assert isinstance(ground_truth[\"gt_parses\"], list)\n",
    "#                 gt_jsons = ground_truth[\"gt_parses\"]\n",
    "#             else:\n",
    "#                 assert \"gt_parse\" in ground_truth and isinstance(\n",
    "#                     ground_truth[\"gt_parse\"], dict\n",
    "#                 )\n",
    "#                 gt_jsons = [ground_truth[\"gt_parse\"]]\n",
    "\n",
    "#             self.gt_token_sequences.append(\n",
    "#                 [\n",
    "#                     self.json2token(\n",
    "#                         gt_json,\n",
    "#                         update_special_tokens_for_json_key=self.split == \"train\",\n",
    "#                         sort_json_key=self.sort_json_key,\n",
    "#                     )\n",
    "#                     + processor.tokenizer.eos_token\n",
    "#                     for gt_json in gt_jsons  # load json from list of json\n",
    "#                 ]\n",
    "#             )\n",
    "\n",
    "#         self.add_tokens([self.task_start_token, self.prompt_end_token])\n",
    "#         self.prompt_end_token_id = processor.tokenizer.convert_tokens_to_ids(\n",
    "#             self.prompt_end_token\n",
    "#         )\n",
    "\n",
    "#     def json2token(\n",
    "#         self,\n",
    "#         obj: Any,\n",
    "#         update_special_tokens_for_json_key: bool = True,\n",
    "#         sort_json_key: bool = True,\n",
    "#     ):\n",
    "#         \"\"\"\n",
    "#         Convert an ordered JSON object into a token sequence\n",
    "#         \"\"\"\n",
    "#         if type(obj) == dict:\n",
    "#             if len(obj) == 1 and \"text_sequence\" in obj:\n",
    "#                 return obj[\"text_sequence\"]\n",
    "#             else:\n",
    "#                 output = \"\"\n",
    "#                 if sort_json_key:\n",
    "#                     keys = sorted(obj.keys(), reverse=True)\n",
    "#                 else:\n",
    "#                     keys = obj.keys()\n",
    "#                 for k in keys:\n",
    "#                     if update_special_tokens_for_json_key:\n",
    "#                         self.add_tokens([rf\"<s_{k}>\", rf\"</s_{k}>\"])\n",
    "#                     output += (\n",
    "#                         rf\"<s_{k}>\"\n",
    "#                         + self.json2token(\n",
    "#                             obj[k], update_special_tokens_for_json_key, sort_json_key\n",
    "#                         )\n",
    "#                         + rf\"</s_{k}>\"\n",
    "#                     )\n",
    "#                 return output\n",
    "#         elif type(obj) == list:\n",
    "#             return r\"<sep/>\".join(\n",
    "#                 [\n",
    "#                     self.json2token(\n",
    "#                         item, update_special_tokens_for_json_key, sort_json_key\n",
    "#                     )\n",
    "#                     for item in obj\n",
    "#                 ]\n",
    "#             )\n",
    "#         else:\n",
    "#             obj = str(obj)\n",
    "#             if f\"<{obj}/>\" in added_tokens:\n",
    "#                 obj = f\"<{obj}/>\"  # for categorical special tokens\n",
    "#             return obj\n",
    "\n",
    "#     def add_tokens(self, list_of_tokens: List[str]):\n",
    "#         \"\"\"\n",
    "#         Add special tokens to tokenizer and resize the token embeddings of the decoder\n",
    "#         \"\"\"\n",
    "#         newly_added_num = processor.tokenizer.add_tokens(list_of_tokens)\n",
    "#         if newly_added_num > 0:\n",
    "#             model.decoder.resize_token_embeddings(len(processor.tokenizer))\n",
    "#             added_tokens.extend(list_of_tokens)\n",
    "\n",
    "#     def __len__(self) -> int:\n",
    "#         return self.dataset_length\n",
    "\n",
    "#     def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "#         \"\"\"\n",
    "#         Load image from image_path of given dataset_path and convert into input_tensor and labels\n",
    "#         Convert gt data into input_ids (tokenized string)\n",
    "#         Returns:\n",
    "#             input_tensor : preprocessed image\n",
    "#             input_ids : tokenized gt_data\n",
    "#             labels : masked labels (model doesn't need to predict prompt and pad token)\n",
    "#         \"\"\"\n",
    "#         sample = self.dataset[idx]\n",
    "\n",
    "#         # inputs\n",
    "#         pixel_values = processor(\n",
    "#             sample[\"image\"], random_padding=self.split == \"train\", return_tensors=\"pt\"\n",
    "#         ).pixel_values\n",
    "#         pixel_values = pixel_values.squeeze()\n",
    "\n",
    "#         # targets\n",
    "#         target_sequence = random.choice(\n",
    "#             self.gt_token_sequences[idx]\n",
    "#         )  # can be more than one, e.g., DocVQA Task 1\n",
    "#         input_ids = processor.tokenizer(\n",
    "#             target_sequence,\n",
    "#             add_special_tokens=False,\n",
    "#             max_length=self.max_length,\n",
    "#             padding=\"max_length\",\n",
    "#             truncation=True,\n",
    "#             return_tensors=\"pt\",\n",
    "#         )[\"input_ids\"].squeeze(0)\n",
    "\n",
    "#         labels = input_ids.clone()\n",
    "#         labels[labels == processor.tokenizer.pad_token_id] = (\n",
    "#             self.ignore_id\n",
    "#         )  # model doesn't need to predict pad token\n",
    "#         # labels[: torch.nonzero(labels == self.prompt_end_token_id).sum() + 1] = self.ignore_id  # model doesn't need to predict prompt (for VQA)\n",
    "#         return pixel_values, labels, target_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we update some settings which differ from pretraining; namely the size of the images + no rotation required\n",
    "# source: https://github.com/clovaai/donut/blob/master/config/train_cord.yaml\n",
    "processor.feature_extractor.size = image_size[::-1]  # should be (width, height)\n",
    "processor.feature_extractor.do_align_long_axis = False\n",
    "import os\n",
    "from donut_dataset import DonutDataset\n",
    "\n",
    "# os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "train_dataset = DonutDataset(\n",
    "    \"mousserlane/id_receipt_dataset\",\n",
    "    max_length=max_length,\n",
    "    split=\"train\",\n",
    "    task_start_token=\"<s_receipt-v1>\",\n",
    "    prompt_end_token=\"<s_receipt-v1>\",\n",
    "    sort_json_key=False,  # cord dataset is preprocessed, so no need for this\n",
    "    processor=processor,\n",
    "    model=model,\n",
    ")\n",
    "val_dataset = DonutDataset(\n",
    "    \"mousserlane/id_receipt_dataset\",\n",
    "    max_length=max_length,\n",
    "    split=\"validation\",\n",
    "    task_start_token=\"<s_receipt-v1>\",\n",
    "    prompt_end_token=\"<s_receipt-v1>\",\n",
    "    sort_json_key=False,  # cord dataset is preprocessed, so no need for this\n",
    "    processor=processor,\n",
    "    model=model,\n",
    ")\n",
    "# if __name__ == \"__main__\":\n",
    "#     train_dataset = DonutDataset(\n",
    "#         \"mousserlane/id_receipt_dataset\",\n",
    "#         max_length=max_length,\n",
    "#         split=\"train\",\n",
    "#         task_start_token=\"<s_receipt-v1>\",\n",
    "#         prompt_end_token=\"<s_receipt-v1>\",\n",
    "#         sort_json_key=False,  # cord dataset is preprocessed, so no need for this\n",
    "#     )\n",
    "\n",
    "#     val_dataset = DonutDataset(\n",
    "#         \"mousserlane/id_receipt_dataset\",\n",
    "#         max_length=max_length,\n",
    "#         split=\"validation\",\n",
    "#         task_start_token=\"<s_receipt-v1>\",\n",
    "#         prompt_end_token=\"<s_receipt-v1>\",\n",
    "#         sort_json_key=False,  # cord dataset is preprocessed, so no need for this\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "added_tokens = train_dataset.get_token()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(added_tokens)\n",
    "print(\"added_tokens\", added_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(processor.tokenizer)\n",
    "print(processor.tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "processor.tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pixel_values, labels, target_sequence = train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(pixel_values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for id in labels.tolist()[:30]:\n",
    "    if id != -100:\n",
    "        print(processor.decode([id]))\n",
    "    else:\n",
    "        print(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(target_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.config.pad_token_id = processor.tokenizer.pad_token_id\n",
    "model.config.decoder_start_token_id = processor.tokenizer.convert_tokens_to_ids(\n",
    "    [\"<s_receipt-v1>\"]\n",
    ")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Pad token ID:\", processor.decode([model.config.pad_token_id]))\n",
    "print(\n",
    "    \"Decoder start token ID:\", processor.decode([model.config.decoder_start_token_id])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Create PyTorch DataLoaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "# feel free to increase the batch size if you have a lot of memory\n",
    "# I'm fine-tuning on Colab and given the large image size, batch size > 1 is not feasible\n",
    "# Set num_workers=4\n",
    "multiprocessing_context = \"fork\" if torch.backends.mps.is_available() else None\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    # multiprocessing_context=multiprocessing_context,\n",
    ")\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    # multiprocessing_context=multiprocessing_context,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataloader <torch.utils.data.dataloader.DataLoader object at 0x1695a6aa0>\n",
      "torch.Size([1, 3, 1280, 960])\n"
     ]
    }
   ],
   "source": [
    "print(\"train dataloader\", train_dataloader)\n",
    "batch = next(iter(train_dataloader))\n",
    "pixel_values, labels, target_sequences = batch\n",
    "print(pixel_values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s_header>\n",
      "<s_restaurant_name>\n",
      "D\n",
      "jour\n",
      "nal\n",
      "</s_restaurant_name>\n",
      "<s_date>\n",
      "22-\n",
      "04\n",
      "-20\n",
      "24\n",
      "13\n",
      ":59\n",
      "</s_date>\n",
      "</s_header>\n",
      "<s_items>\n",
      "<s_item_qty>\n",
      "1\n",
      "</s_item_qty>\n",
      "<s_item_name>\n",
      "Salt\n",
      "ed\n",
      "Cara\n",
      "mel\n",
      "La\n",
      "tte\n",
      "</s_item_name>\n",
      "<s_item_price>\n",
      "4\n",
      "9.000\n"
     ]
    }
   ],
   "source": [
    "for id in labels.squeeze().tolist()[:30]:\n",
    "    if id != -100:\n",
    "        print(processor.decode([id]))\n",
    "    else:\n",
    "        print(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset))\n",
    "print(len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 1280, 960])\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(val_dataloader))\n",
    "pixel_values, labels, target_sequences = batch\n",
    "print(pixel_values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s_header><s_restaurant_name>Yakiniku Like Grand Indonesia</s_restaurant_name><s_date>27-01-2024 12:21</s_date></s_header><s_items><s_item_qty>1</s_item_qty><s_item_name>COUPLE SET 300GR</s_item_name><s_item_price>269.000</s_item_price><s_subitems><s_item_qty>1</s_item_qty><s_item_name>OCHA COLD (Free Refill)</s_item_name><s_item_price>15.000</s_item_price></s_subitems><sep/><s_item_qty>1</s_item_qty><s_item_name>OCHA HOT (Free Refill)</s_item_name><s_item_price>15.000</s_item_price></s_items><s_subtotal>299.000</s_subtotal><s_service>8.970</s_service><s_tax>30.797</s_tax><s_total>338.767</s_total></s>\n"
     ]
    }
   ],
   "source": [
    "print(target_sequences[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Define LightingModule\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "from nltk import edit_distance\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.utilities import rank_zero_only\n",
    "\n",
    "\n",
    "class DonutModelPLModule(pl.LightningModule):\n",
    "    def __init__(self, config, processor, model):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.processor = processor\n",
    "        self.model = model\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        pixel_values, labels, _ = batch\n",
    "\n",
    "        outputs = self.model(pixel_values, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        self.log_dict({\"train_loss\": loss}, sync_dist=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx, dataset_idx=0):\n",
    "        pixel_values, labels, answers = batch\n",
    "        batch_size = pixel_values.shape[0]\n",
    "        # we feed the prompt to the model\n",
    "        decoder_input_ids = torch.full(\n",
    "            (batch_size, 1),\n",
    "            self.model.config.decoder_start_token_id,\n",
    "            device=self.device,\n",
    "        )\n",
    "\n",
    "        outputs = self.model.generate(\n",
    "            pixel_values,\n",
    "            decoder_input_ids=decoder_input_ids,\n",
    "            max_length=max_length,\n",
    "            early_stopping=True,\n",
    "            pad_token_id=self.processor.tokenizer.pad_token_id,\n",
    "            eos_token_id=self.processor.tokenizer.eos_token_id,\n",
    "            use_cache=True,\n",
    "            num_beams=1,\n",
    "            bad_words_ids=[[self.processor.tokenizer.unk_token_id]],\n",
    "            return_dict_in_generate=True,\n",
    "        )\n",
    "\n",
    "        predictions = []\n",
    "        for seq in self.processor.tokenizer.batch_decode(outputs.sequences):\n",
    "            seq = seq.replace(self.processor.tokenizer.eos_token, \"\").replace(\n",
    "                self.processor.tokenizer.pad_token, \"\"\n",
    "            )\n",
    "            seq = re.sub(\n",
    "                r\"<.*?>\", \"\", seq, count=1\n",
    "            ).strip()  # remove first task start token\n",
    "            predictions.append(seq)\n",
    "\n",
    "        scores = list()\n",
    "        for pred, answer in zip(predictions, answers):\n",
    "            pred = re.sub(r\"(?:(?<=>) | (?=</s_))\", \"\", pred)\n",
    "            # NOT NEEDED ANYMORE\n",
    "            # answer = re.sub(r\"<.*?>\", \"\", answer, count=1)\n",
    "            answer = answer.replace(self.processor.tokenizer.eos_token, \"\")\n",
    "            scores.append(edit_distance(pred, answer) / max(len(pred), len(answer)))\n",
    "\n",
    "            if self.config.get(\"verbose\", False) and len(scores) == 1:\n",
    "                print(f\"Prediction: {pred}\")\n",
    "                print(f\"    Answer: {answer}\")\n",
    "                print(f\" Normed ED: {scores[0]}\")\n",
    "\n",
    "        return scores\n",
    "\n",
    "    def validation_epoch_end(self, validation_step_outputs):\n",
    "        # I set this to 1 manually\n",
    "        # (previously set to len(self.config.dataset_name_or_paths))\n",
    "        num_of_loaders = 1\n",
    "        if num_of_loaders == 1:\n",
    "            validation_step_outputs = [validation_step_outputs]\n",
    "        assert len(validation_step_outputs) == num_of_loaders\n",
    "        cnt = [0] * num_of_loaders\n",
    "        total_metric = [0] * num_of_loaders\n",
    "        val_metric = [0] * num_of_loaders\n",
    "        for i, results in enumerate(validation_step_outputs):\n",
    "            for scores in results:\n",
    "                cnt[i] += len(scores)\n",
    "                total_metric[i] += np.sum(scores)\n",
    "            val_metric[i] = total_metric[i] / cnt[i]\n",
    "            val_metric_name = f\"val_metric_{i}th_dataset\"\n",
    "            self.log_dict({val_metric_name: val_metric[i]}, sync_dist=True)\n",
    "        self.log_dict(\n",
    "            {\"val_metric\": np.sum(total_metric) / np.sum(cnt)}, sync_dist=True\n",
    "        )\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # TODO add scheduler\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.config.get(\"lr\"))\n",
    "\n",
    "        return optimizer\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return train_dataloader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return val_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set epochs = 30\n",
    "# Set num_training_samples_per_epoch = training set size\n",
    "config = {\n",
    "    \"max_epochs\": 30,\n",
    "    \"val_check_interval\": 0.4,  # how many times we want to validate during an epoch\n",
    "    \"check_val_every_n_epoch\": 1,\n",
    "    \"gradient_clip_val\": 1.0,\n",
    "    \"num_training_samples_per_epoch\": 425,\n",
    "    \"lr\": 3e-5,\n",
    "    \"train_batch_sizes\": [8],\n",
    "    \"val_batch_sizes\": [1],\n",
    "    # \"seed\":2022,\n",
    "    \"num_nodes\": 1,\n",
    "    \"warmup_steps\": 81,  # 425 / 8 = 54, 54 * 10 = 540, 540 * 0.15 = 81\n",
    "    \"result_path\": \"./result\",\n",
    "    \"verbose\": False,\n",
    "}\n",
    "\n",
    "model_module = DonutModelPLModule(config, processor, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name  | Type                      | Params\n",
      "----------------------------------------------------\n",
      "0 | model | VisionEncoderDecoderModel | 201 M \n",
      "----------------------------------------------------\n",
      "201 M     Trainable params\n",
      "0         Non-trainable params\n",
      "201 M     Total params\n",
      "807.535   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  22%|██▏       | 4/18 [00:47<02:45, 11.80s/it, loss=12.3, v_num=12]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mousserlane/Codes/work/sb-sparrow-donut/.sb-sparrow-donut/lib/python3.10/site-packages/transformers/generation/utils.py:1338: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
      "  warnings.warn(\n",
      "/Users/mousserlane/Codes/work/sb-sparrow-donut/.sb-sparrow-donut/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:641: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/18 [05:09<?, ?it/s]1.25s/it, loss=10.6, v_num=12]\n",
      "Epoch 0: 100%|██████████| 18/18 [03:23<00:00, 11.31s/it, loss=9.71, v_num=12]Pushing model to the hub, epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors: 100%|██████████| 809M/809M [02:13<00:00, 6.05MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  22%|██▏       | 4/18 [00:53<03:08, 13.43s/it, loss=9.14, v_num=12] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mousserlane/Codes/work/sb-sparrow-donut/.sb-sparrow-donut/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:641: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 18/18 [05:35<00:00, 18.64s/it, loss=7.45, v_num=12]Pushing model to the hub, epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors: 100%|██████████| 809M/809M [01:54<00:00, 7.06MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:  22%|██▏       | 4/18 [00:50<02:56, 12.62s/it, loss=6.88, v_num=12] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mousserlane/Codes/work/sb-sparrow-donut/.sb-sparrow-donut/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:641: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 18/18 [05:40<00:00, 18.93s/it, loss=6.08, v_num=12]Pushing model to the hub, epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors: 100%|██████████| 809M/809M [01:45<00:00, 7.66MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3:  22%|██▏       | 4/18 [00:53<03:06, 13.31s/it, loss=5.61, v_num=12] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mousserlane/Codes/work/sb-sparrow-donut/.sb-sparrow-donut/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:641: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 18/18 [05:54<00:00, 19.69s/it, loss=4.75, v_num=12]Pushing model to the hub, epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors: 100%|██████████| 809M/809M [01:40<00:00, 8.02MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4:  22%|██▏       | 4/18 [00:53<03:07, 13.40s/it, loss=4.11, v_num=12] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mousserlane/Codes/work/sb-sparrow-donut/.sb-sparrow-donut/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:641: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 18/18 [05:59<00:00, 19.99s/it, loss=3.31, v_num=12]Pushing model to the hub, epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors: 100%|██████████| 809M/809M [01:38<00:00, 8.20MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5:  22%|██▏       | 4/18 [00:53<03:08, 13.44s/it, loss=2.99, v_num=12] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mousserlane/Codes/work/sb-sparrow-donut/.sb-sparrow-donut/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:641: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 18/18 [04:50<00:00, 16.14s/it, loss=2.27, v_num=12]Pushing model to the hub, epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors: 100%|██████████| 809M/809M [03:50<00:00, 3.50MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6:  22%|██▏       | 4/18 [00:54<03:09, 13.56s/it, loss=1.99, v_num=12] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mousserlane/Codes/work/sb-sparrow-donut/.sb-sparrow-donut/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:641: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 18/18 [05:01<00:00, 16.72s/it, loss=1.55, v_num=12]Pushing model to the hub, epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors: 100%|██████████| 809M/809M [09:07<00:00, 1.48MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7:  22%|██▏       | 4/18 [00:56<03:16, 14.05s/it, loss=1.44, v_num=12] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mousserlane/Codes/work/sb-sparrow-donut/.sb-sparrow-donut/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:641: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 18/18 [03:58<00:00, 13.27s/it, loss=1.38, v_num=12]Pushing model to the hub, epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors: 100%|██████████| 809M/809M [08:17<00:00, 1.63MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8:  22%|██▏       | 4/18 [00:55<03:13, 13.84s/it, loss=1.23, v_num=12] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mousserlane/Codes/work/sb-sparrow-donut/.sb-sparrow-donut/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:641: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 18/18 [03:34<00:00, 11.89s/it, loss=1.06, v_num=12]Pushing model to the hub, epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors: 100%|██████████| 809M/809M [07:11<00:00, 1.87MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9:  22%|██▏       | 4/18 [00:54<03:10, 13.59s/it, loss=0.764, v_num=12]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mousserlane/Codes/work/sb-sparrow-donut/.sb-sparrow-donut/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:641: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 18/18 [03:27<00:00, 11.52s/it, loss=0.724, v_num=12]Pushing model to the hub, epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors: 100%|██████████| 809M/809M [09:32<00:00, 1.41MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10:  22%|██▏       | 4/18 [00:54<03:10, 13.60s/it, loss=0.709, v_num=12]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mousserlane/Codes/work/sb-sparrow-donut/.sb-sparrow-donut/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:641: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 18/18 [03:26<00:00, 11.49s/it, loss=0.667, v_num=12]Pushing model to the hub, epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors: 100%|██████████| 809M/809M [07:04<00:00, 1.90MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11:  22%|██▏       | 4/18 [00:51<02:58, 12.77s/it, loss=0.556, v_num=12] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mousserlane/Codes/work/sb-sparrow-donut/.sb-sparrow-donut/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:641: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 18/18 [03:14<00:00, 10.79s/it, loss=0.505, v_num=12]Pushing model to the hub, epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors: 100%|██████████| 809M/809M [09:38<00:00, 1.40MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12:  22%|██▏       | 4/18 [00:49<02:54, 12.45s/it, loss=0.441, v_num=12] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mousserlane/Codes/work/sb-sparrow-donut/.sb-sparrow-donut/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:641: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 18/18 [03:12<00:00, 10.70s/it, loss=0.402, v_num=12]Pushing model to the hub, epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors: 100%|██████████| 809M/809M [09:19<00:00, 1.45MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13:  22%|██▏       | 4/18 [00:48<02:49, 12.12s/it, loss=0.339, v_num=12] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mousserlane/Codes/work/sb-sparrow-donut/.sb-sparrow-donut/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:641: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 18/18 [03:10<00:00, 10.60s/it, loss=0.44, v_num=12] Pushing model to the hub, epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors: 100%|██████████| 809M/809M [10:35<00:00, 1.27MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14:  22%|██▏       | 4/18 [00:49<02:54, 12.44s/it, loss=0.443, v_num=12]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mousserlane/Codes/work/sb-sparrow-donut/.sb-sparrow-donut/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:641: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 18/18 [03:07<00:00, 10.44s/it, loss=0.457, v_num=12]Pushing model to the hub, epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors: 100%|██████████| 809M/809M [10:34<00:00, 1.28MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15:  22%|██▏       | 4/18 [00:47<02:44, 11.79s/it, loss=0.344, v_num=12] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mousserlane/Codes/work/sb-sparrow-donut/.sb-sparrow-donut/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:641: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 18/18 [03:02<00:00, 10.15s/it, loss=0.305, v_num=12]Pushing model to the hub, epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors: 100%|██████████| 809M/809M [06:35<00:00, 2.05MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16:  22%|██▏       | 4/18 [00:46<02:44, 11.73s/it, loss=0.259, v_num=12] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mousserlane/Codes/work/sb-sparrow-donut/.sb-sparrow-donut/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:641: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 18/18 [03:03<00:00, 10.22s/it, loss=0.234, v_num=12]Pushing model to the hub, epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors: 100%|██████████| 809M/809M [03:10<00:00, 4.24MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17:  22%|██▏       | 4/18 [00:47<02:47, 11.93s/it, loss=0.225, v_num=12] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mousserlane/Codes/work/sb-sparrow-donut/.sb-sparrow-donut/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:641: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 18/18 [03:07<00:00, 10.40s/it, loss=0.225, v_num=12]Pushing model to the hub, epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors: 100%|██████████| 809M/809M [03:32<00:00, 3.82MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18:  22%|██▏       | 4/18 [00:47<02:46, 11.88s/it, loss=0.226, v_num=12] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mousserlane/Codes/work/sb-sparrow-donut/.sb-sparrow-donut/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:641: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 18/18 [03:07<00:00, 10.40s/it, loss=0.289, v_num=12]Pushing model to the hub, epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors: 100%|██████████| 809M/809M [03:22<00:00, 3.99MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19:  22%|██▏       | 4/18 [00:46<02:42, 11.61s/it, loss=0.318, v_num=12] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mousserlane/Codes/work/sb-sparrow-donut/.sb-sparrow-donut/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:641: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 18/18 [03:01<00:00, 10.08s/it, loss=0.291, v_num=12]Pushing model to the hub, epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors: 100%|██████████| 809M/809M [03:10<00:00, 4.25MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20:  22%|██▏       | 4/18 [00:48<02:49, 12.08s/it, loss=0.22, v_num=12]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mousserlane/Codes/work/sb-sparrow-donut/.sb-sparrow-donut/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:641: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 18/18 [03:07<00:00, 10.39s/it, loss=0.169, v_num=12]Pushing model to the hub, epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors: 100%|██████████| 809M/809M [03:54<00:00, 3.45MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21:  22%|██▏       | 4/18 [00:47<02:47, 11.96s/it, loss=0.177, v_num=12] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mousserlane/Codes/work/sb-sparrow-donut/.sb-sparrow-donut/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:641: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 18/18 [03:03<00:00, 10.17s/it, loss=0.18, v_num=12] Pushing model to the hub, epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors: 100%|██████████| 809M/809M [04:17<00:00, 3.15MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22:  22%|██▏       | 4/18 [00:47<02:45, 11.80s/it, loss=0.171, v_num=12]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mousserlane/Codes/work/sb-sparrow-donut/.sb-sparrow-donut/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:641: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 18/18 [03:02<00:00, 10.13s/it, loss=0.153, v_num=12]Pushing model to the hub, epoch 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors: 100%|██████████| 809M/809M [02:25<00:00, 5.55MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23:  22%|██▏       | 4/18 [00:47<02:45, 11.83s/it, loss=0.149, v_num=12] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mousserlane/Codes/work/sb-sparrow-donut/.sb-sparrow-donut/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:641: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 18/18 [03:02<00:00, 10.15s/it, loss=0.152, v_num=12]Pushing model to the hub, epoch 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors: 100%|██████████| 809M/809M [02:04<00:00, 6.51MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24:  22%|██▏       | 4/18 [00:48<02:49, 12.12s/it, loss=0.139, v_num=12] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mousserlane/Codes/work/sb-sparrow-donut/.sb-sparrow-donut/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:641: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 18/18 [02:58<00:00,  9.91s/it, loss=0.158, v_num=12]Pushing model to the hub, epoch 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors: 100%|██████████| 809M/809M [02:29<00:00, 5.40MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25:  22%|██▏       | 4/18 [00:47<02:47, 11.94s/it, loss=0.16, v_num=12]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mousserlane/Codes/work/sb-sparrow-donut/.sb-sparrow-donut/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:641: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 18/18 [03:02<00:00, 10.16s/it, loss=0.135, v_num=12]Pushing model to the hub, epoch 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors: 100%|██████████| 809M/809M [02:29<00:00, 5.42MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26:  22%|██▏       | 4/18 [00:47<02:46, 11.92s/it, loss=0.107, v_num=12] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mousserlane/Codes/work/sb-sparrow-donut/.sb-sparrow-donut/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:641: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|██████████| 18/18 [03:02<00:00, 10.17s/it, loss=0.0779, v_num=12]Pushing model to the hub, epoch 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors: 100%|██████████| 809M/809M [02:09<00:00, 6.24MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27:  22%|██▏       | 4/18 [00:45<02:40, 11.45s/it, loss=0.0695, v_num=12] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mousserlane/Codes/work/sb-sparrow-donut/.sb-sparrow-donut/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:641: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|██████████| 18/18 [03:00<00:00, 10.03s/it, loss=0.0923, v_num=12]Pushing model to the hub, epoch 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors: 100%|██████████| 809M/809M [02:23<00:00, 5.64MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28:  22%|██▏       | 4/18 [00:46<02:42, 11.62s/it, loss=0.106, v_num=12]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mousserlane/Codes/work/sb-sparrow-donut/.sb-sparrow-donut/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:641: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|██████████| 18/18 [03:00<00:00, 10.05s/it, loss=0.107, v_num=12]Pushing model to the hub, epoch 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors: 100%|██████████| 809M/809M [02:13<00:00, 6.07MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29:  22%|██▏       | 4/18 [00:47<02:46, 11.87s/it, loss=0.0934, v_num=12]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mousserlane/Codes/work/sb-sparrow-donut/.sb-sparrow-donut/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:641: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 18/18 [03:04<00:00, 10.23s/it, loss=0.0695, v_num=12]Pushing model to the hub, epoch 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors: 100%|██████████| 809M/809M [02:17<00:00, 5.89MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 18/18 [05:29<00:00, 18.30s/it, loss=0.0695, v_num=12]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pushing model to the hub after training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece.bpe.model: 100%|██████████| 1.30M/1.30M [00:00<00:00, 2.43MB/s]\n",
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 18/18 [05:37<00:00, 18.73s/it, loss=0.0695, v_num=12]\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks import Callback\n",
    "\n",
    "# wandb_logger = WandbLogger(project=\"Splitbill.id\", name=\"receipt-parser-v1\")\n",
    "\n",
    "\n",
    "class PushToHubCallback(Callback):\n",
    "    def on_train_epoch_end(self, trainer, pl_module):\n",
    "        print(f\"Pushing model to the hub, epoch {trainer.current_epoch}\")\n",
    "        pl_module.model.push_to_hub(\n",
    "            \"mousserlane/sb-donut-receipt-parser-v1\",\n",
    "            commit_message=f\"Training in progress, epoch {trainer.current_epoch}\",\n",
    "        )\n",
    "\n",
    "    def on_train_end(self, trainer, pl_module):\n",
    "        print(f\"Pushing model to the hub after training\")\n",
    "        pl_module.processor.push_to_hub(\n",
    "            \"mousserlane/sb-donut-receipt-parser-v1\", commit_message=f\"Training done\"\n",
    "        )\n",
    "        pl_module.model.push_to_hub(\n",
    "            \"mousserlane/sb-donut-receipt-parser-v1\", commit_message=f\"Training done\"\n",
    "        )\n",
    "\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    accelerator=\"cpu\",\n",
    "    devices=1,\n",
    "    max_epochs=config.get(\"max_epochs\"),\n",
    "    val_check_interval=config.get(\"val_check_interval\"),\n",
    "    check_val_every_n_epoch=config.get(\"check_val_every_n_epoch\"),\n",
    "    gradient_clip_val=config.get(\"gradient_clip_val\"),\n",
    "    # precision=16,  # we'll use mixed precision\n",
    "    num_sanity_val_steps=0,\n",
    "    # logger=wandb_logger,\n",
    "    callbacks=[PushToHubCallback()],\n",
    ")\n",
    "\n",
    "trainer.fit(model_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from transformers import DonutProcessor, VisionEncoderDecoderModel\n",
    "\n",
    "processor = DonutProcessor.from_pretrained(\"mousserlane/sb-donut-receipt-parser-v1\")\n",
    "model = VisionEncoderDecoderModel.from_pretrained(\n",
    "    \"mousserlane/sb-donut-receipt-parser-v1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mousserlane/Codes/work/sb-sparrow-donut/.sb-sparrow-donut/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:641: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n",
      "100%|██████████| 4/4 [00:16<00:00,  4.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracies': [0.06862745098039214, 1.0, 1.0, 0.752442996742671], 'mean_accuracy': 0.7052676119307657} length : 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "\n",
    "from donut import JSONParseEvaluator\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "output_list = []\n",
    "accs = []\n",
    "\n",
    "dataset = load_dataset(\"mousserlane/id_receipt_dataset\", split=\"test\")\n",
    "\n",
    "for idx, sample in tqdm(enumerate(dataset), total=len(dataset)):\n",
    "    # prepare encoder inputs\n",
    "    pixel_values = processor(\n",
    "        sample[\"image\"].convert(\"RGB\"), return_tensors=\"pt\"\n",
    "    ).pixel_values\n",
    "    pixel_values = pixel_values.to(device)\n",
    "    # prepare decoder inputs\n",
    "    task_prompt = \"<s_receipt-v1>\"\n",
    "    decoder_input_ids = processor.tokenizer(\n",
    "        task_prompt, add_special_tokens=False, return_tensors=\"pt\"\n",
    "    ).input_ids\n",
    "    decoder_input_ids = decoder_input_ids.to(device)\n",
    "\n",
    "    # autoregressively generate sequence\n",
    "    outputs = model.generate(\n",
    "        pixel_values,\n",
    "        decoder_input_ids=decoder_input_ids,\n",
    "        max_length=model.decoder.config.max_position_embeddings,\n",
    "        early_stopping=True,\n",
    "        pad_token_id=processor.tokenizer.pad_token_id,\n",
    "        eos_token_id=processor.tokenizer.eos_token_id,\n",
    "        use_cache=True,\n",
    "        num_beams=1,\n",
    "        bad_words_ids=[[processor.tokenizer.unk_token_id]],\n",
    "        return_dict_in_generate=True,\n",
    "    )\n",
    "\n",
    "    # turn into JSON\n",
    "    seq = processor.batch_decode(outputs.sequences)[0]\n",
    "    seq = seq.replace(processor.tokenizer.eos_token, \"\").replace(\n",
    "        processor.tokenizer.pad_token, \"\"\n",
    "    )\n",
    "    seq = re.sub(r\"<.*?>\", \"\", seq, count=1).strip()  # remove first task start token\n",
    "    seq = processor.token2json(seq)\n",
    "\n",
    "    ground_truth = json.loads(sample[\"ground_truth\"])\n",
    "    ground_truth = ground_truth[\"gt_parse\"]\n",
    "    evaluator = JSONParseEvaluator()\n",
    "    score = evaluator.cal_acc(seq, ground_truth)\n",
    "\n",
    "    accs.append(score)\n",
    "    output_list.append(seq)\n",
    "\n",
    "scores = {\"accuracies\": accs, \"mean_accuracy\": np.mean(accs)}\n",
    "print(scores, f\"length : {len(accs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy: 0.7052676119307657\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean accuracy:\", np.mean(accs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
